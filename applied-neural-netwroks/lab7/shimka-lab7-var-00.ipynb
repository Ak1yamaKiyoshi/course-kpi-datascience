{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akiyama/.conda/envs/base310/lib/python3.10/site-packages/torchtext/datasets/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/home/akiyama/.conda/envs/base310/lib/python3.10/site-packages/torchtext/data/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Field' from 'torchtext.data' (/home/akiyama/.conda/envs/base310/lib/python3.10/site-packages/torchtext/data/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YelpReviewPolarity\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Field, BucketIterator\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvocab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GloVe\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Define the text field and load the GloVe embeddings\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Field' from 'torchtext.data' (/home/akiyama/.conda/envs/base310/lib/python3.10/site-packages/torchtext/data/__init__.py)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from jiwer import wer\n",
    "\n",
    "\n",
    "data_url = \"https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\"\n",
    "data_path = keras.utils.get_file(\"LJSpeech-1.1\", data_url, untar=True)\n",
    "wavs_path = data_path + \"/wavs/\"\n",
    "metadata_path = data_path + \"/metadata.csv\"\n",
    "\n",
    "\n",
    "# Read metadata file and parse it\n",
    "metadata_df = pd.read_csv(metadata_path, sep=\"|\", header=None, quoting=3)\n",
    "metadata_df.columns = [\"file_name\", \"transcription\", \"normalized_transcription\"]\n",
    "metadata_df = metadata_df[[\"file_name\", \"normalized_transcription\"]]\n",
    "metadata_df = metadata_df.sample(frac=1).reset_index(drop=True)\n",
    "metadata_df.head(3)\n",
    "\n",
    "split = int(len(metadata_df) * 0.90)\n",
    "df_train = metadata_df[:split]\n",
    "df_val = metadata_df[split:]\n",
    "\n",
    "print(f\"Size of the training set: {len(df_train)}\")\n",
    "print(f\"Size of the training set: {len(df_val)}\")\n",
    "\n",
    "\n",
    "# The set of characters accepted in the transcription.\n",
    "characters = [x for x in \"abcdefghijklmnopqrstuvwxyz'?! \"]\n",
    "# Mapping characters to integers\n",
    "char_to_num = keras.layers.StringLookup(vocabulary=characters, oov_token=\"\")\n",
    "# Mapping integers back to original characters\n",
    "num_to_char = keras.layers.StringLookup(\n",
    "    vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"The vocabulary is: {char_to_num.get_vocabulary()} \"\n",
    "    f\"(size ={char_to_num.vocabulary_size()})\"\n",
    ")\n",
    "# An integer scalar Tensor. The window length in samples.\n",
    "frame_length = 256\n",
    "# An integer scalar Tensor. The number of samples to step.\n",
    "frame_step = 160\n",
    "# An integer scalar Tensor. The size of the FFT to apply.\n",
    "# If not provided, uses the smallest power of 2 enclosing frame_length.\n",
    "fft_length = 384\n",
    "\n",
    "\n",
    "def encode_single_sample(wav_file, label):\n",
    "    ###########################################\n",
    "    ##  Process the Audio\n",
    "    ##########################################\n",
    "    # 1. Read wav file\n",
    "    file = tf.io.read_file(wavs_path + wav_file + \".wav\")\n",
    "    # 2. Decode the wav file\n",
    "    audio, _ = tf.audio.decode_wav(file)\n",
    "    audio = tf.squeeze(audio, axis=-1)\n",
    "    # 3. Change type to float\n",
    "    audio = tf.cast(audio, tf.float32)\n",
    "    # 4. Get the spectrogram\n",
    "    spectrogram = tf.signal.stft(\n",
    "        audio, frame_length=frame_length, frame_step=frame_step, fft_length=fft_length\n",
    "    )\n",
    "    # 5. We only need the magnitude, which can be derived by applying tf.abs\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    spectrogram = tf.math.pow(spectrogram, 0.5)\n",
    "    # 6. normalisation\n",
    "    means = tf.math.reduce_mean(spectrogram, 1, keepdims=True)\n",
    "    stddevs = tf.math.reduce_std(spectrogram, 1, keepdims=True)\n",
    "    spectrogram = (spectrogram - means) / (stddevs + 1e-10)\n",
    "    ###########################################\n",
    "    ##  Process the label\n",
    "    ##########################################\n",
    "    # 7. Convert label to Lower case\n",
    "    label = tf.strings.lower(label)\n",
    "    # 8. Split the label\n",
    "    label = tf.strings.unicode_split(label, input_encoding=\"UTF-8\")\n",
    "    # 9. Map the characters in label to numbers\n",
    "    label = char_to_num(label)\n",
    "    # 10. Return a dict as our model is expecting two inputs\n",
    "    return spectrogram, label\n",
    "batch_size = 32\n",
    "# Define the training dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (list(df_train[\"file_name\"]), list(df_train[\"normalized_transcription\"]))\n",
    ")\n",
    "train_dataset = (\n",
    "    train_dataset.map(encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .padded_batch(batch_size)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "# Define the validation dataset\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (list(df_val[\"file_name\"]), list(df_val[\"normalized_transcription\"]))\n",
    ")\n",
    "validation_dataset = (\n",
    "    validation_dataset.map(encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .padded_batch(batch_size)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "model = keras.Sequential([\n",
    "    # Додайте згорткові шари для витягування ознак\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(None, 129, 1)),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Додайте LSTM шари для аналізу послідовностей ознак\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(128, return_sequences=True)),\n",
    "    # Подайте результати LSTM на повний зв'язаний шар\n",
    "    keras.layers.Dense(len(characters) + 1, activation='softmax')\n",
    "])\n",
    "\n",
    "# Компіляція моделі\n",
    "model.compile(optimizer='adam',\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Виведіть структуру моделі\n",
    "model.summary()\n",
    "\n",
    "# Тренуйте модель\n",
    "history = model.fit(train_dataset, epochs=10, validation_data=validation_dataset)\n",
    "\n",
    "# Оцініть модель\n",
    "loss, accuracy = model.evaluate(validation_dataset)\n",
    "print(\"Validation Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
